{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e90f0fb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_579130/1159958401.py:12\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [char \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016 \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m en_stop \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m窶能u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m tokens_dem_platform_2016\n\u001b[0;32m---> 12\u001b[0m lemmatized_tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016]\n\u001b[1;32m     13\u001b[0m lemmatized_tokens_dem_platform_2016\n",
      "File \u001b[0;32m/tmp/ipykernel_579130/1159958401.py:12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [char \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016 \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m en_stop \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m窶能u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m tokens_dem_platform_2016\n\u001b[0;32m---> 12\u001b[0m lemmatized_tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016]\n\u001b[1;32m     13\u001b[0m lemmatized_tokens_dem_platform_2016\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/stem/wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProjectWebScraping.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2294\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2292\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2294\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/magics/execution.py:717\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2800\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   2798\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cell(cell, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures\u001b[38;5;241m=\u001b[39mshell_futures)\n\u001b[1;32m   2799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 2800\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m   2802\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:240\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_before_exec\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_579130/1159958401.py:12\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [char \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016 \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m en_stop \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m窶能u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m tokens_dem_platform_2016\n\u001b[0;32m---> 12\u001b[0m lemmatized_tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016]\n\u001b[1;32m     13\u001b[0m lemmatized_tokens_dem_platform_2016\n",
      "File \u001b[0;32m/tmp/ipykernel_579130/1159958401.py:12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [char \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016 \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m en_stop \u001b[38;5;129;01mand\u001b[39;00m char \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m窶能u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m tokens_dem_platform_2016\n\u001b[0;32m---> 12\u001b[0m lemmatized_tokens_dem_platform_2016 \u001b[38;5;241m=\u001b[39m [\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens_dem_platform_2016]\n\u001b[1;32m     13\u001b[0m lemmatized_tokens_dem_platform_2016\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/stem/wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%run ProjectWebScraping.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3e8150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mnps_chat\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('nps_chat')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/nps_chat\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnps_chat\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('nps_chat')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/nps_chat.zip/nps_chat/\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/book.py:39\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m text4 \u001b[38;5;241m=\u001b[39m Text(inaugural\u001b[38;5;241m.\u001b[39mwords(), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInaugural Address Corpus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext4:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text4\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m---> 39\u001b[0m text5 \u001b[38;5;241m=\u001b[39m Text(\u001b[43mnps_chat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChat Corpus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext5:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text5\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     42\u001b[0m text6 \u001b[38;5;241m=\u001b[39m Text(webtext\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrail.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonty Python and the Holy Grail\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnps_chat\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('nps_chat')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/nps_chat\u001b[0m\n\n  Searched in:\n    - '/home/maciek/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f6bda5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_dem_platform_2016' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtext_dem_platform_2016\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_dem_platform_2016' is not defined"
     ]
    }
   ],
   "source": [
    "text_dem_platform_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aabaa7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_dem_debate_2016' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtext_dem_debate_2016\u001b[49m\u001b[38;5;241m.\u001b[39mdispersion_plot([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcitizens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemocracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfreedom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduties\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmerica\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_dem_debate_2016' is not defined"
     ]
    }
   ],
   "source": [
    "text_dem_debate_2016.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454db38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dem_platform_2016.count(\"America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468f9156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dem_platform_2016.count(\"imigrantion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c55ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text): \n",
    "...     return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "471245d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(count, total):\n",
    "...     return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1cdf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15718468939552394"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text_dem_platform_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110fd47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2265913686118664"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text_dem_platform_2016.count(\"America\"), len(text_dem_platform_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df10c88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4509"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> vocab = set(text_dem_platform_2016)\n",
    ">>> vocab_size = len(vocab)\n",
    ">>> vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bddcac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist1 = FreqDist(text_dem_platform_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fe673e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 4509 samples and 28686 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52ad9905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1424),\n",
       " ('and', 1404),\n",
       " ('the', 1077),\n",
       " ('.', 1048),\n",
       " ('to', 972),\n",
       " ('of', 662),\n",
       " ('will', 473),\n",
       " ('We', 424),\n",
       " ('in', 383),\n",
       " ('that', 372),\n",
       " ('a', 316),\n",
       " ('for', 312),\n",
       " ('our', 282),\n",
       " ('we', 232),\n",
       " ('is', 200),\n",
       " ('Democrats', 177),\n",
       " ('are', 168),\n",
       " ('with', 161),\n",
       " ('on', 146),\n",
       " ('by', 138),\n",
       " ('their', 136),\n",
       " (\"'s\", 127),\n",
       " ('support', 122),\n",
       " ('believe', 117),\n",
       " ('health', 114),\n",
       " ('as', 114),\n",
       " ('be', 106),\n",
       " ('have', 105),\n",
       " ('people', 102),\n",
       " ('or', 95),\n",
       " ('must', 91),\n",
       " ('more', 89),\n",
       " ('Americans', 89),\n",
       " ('American', 87),\n",
       " ('all', 86),\n",
       " ('not', 84),\n",
       " ('should', 82),\n",
       " ('also', 82),\n",
       " ('communities', 79),\n",
       " ('who', 79),\n",
       " ('from', 77),\n",
       " ('it', 77),\n",
       " ('public', 75),\n",
       " ('work', 71),\n",
       " ('America', 65),\n",
       " ('make', 65),\n",
       " ('they', 64),\n",
       " ('country', 62),\n",
       " ('care', 61),\n",
       " ('other', 60)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common(50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a71dbad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common(50)\n",
    "fdist1[\"America\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6454e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American-Serving',\n",
       " 'Americans窶排egardless',\n",
       " 'Anti-CorruptionDemocrats',\n",
       " 'Asia-PacificFrom',\n",
       " 'Commander-in-Chief',\n",
       " 'CultureDemocrats',\n",
       " 'Entrepreneurship',\n",
       " 'FamiliesDemocrats',\n",
       " 'Hawaiian-Serving',\n",
       " 'HealthInvestment',\n",
       " 'Hispanic-Serving',\n",
       " 'HomeownershipWhereas',\n",
       " 'InfrastructureIf',\n",
       " 'InstitutionsDemocrats',\n",
       " 'Islander-Serving',\n",
       " 'Israeli-Palestinian',\n",
       " 'JusticeDemocrats',\n",
       " 'LeadershipClimate',\n",
       " 'Minority-Serving',\n",
       " 'Non-Proliferation',\n",
       " 'Nuclear-Test-Ban',\n",
       " 'PrivacyDemocrats',\n",
       " 'ProfitsCorporate',\n",
       " 'RealityDemocrats',\n",
       " 'RenaissanceDemocrats',\n",
       " 'ResearchDemocrats',\n",
       " 'RetirementDemocrats',\n",
       " 'SecurityDemocrats',\n",
       " 'ServiceDemocrats',\n",
       " 'SocietyDemocrats',\n",
       " 'TechnologyDemocrats',\n",
       " 'WeaponsDemocrats',\n",
       " 'WorkersDemocrats',\n",
       " 'abortion窶排egardless',\n",
       " 'accountable窶巴ecause',\n",
       " 'anti-competitive',\n",
       " 'assault窶背herever',\n",
       " 'behind窶琶ncluding',\n",
       " 'businesses窶馬early',\n",
       " 'communities窶杷rom',\n",
       " 'counterproductive',\n",
       " 'cradle-to-college',\n",
       " 'culturally-appropriate',\n",
       " 'culturally-based',\n",
       " 'culturally-tailored',\n",
       " 'democratically-elected',\n",
       " 'disproportionate',\n",
       " 'disproportionately',\n",
       " 'economy窶琶ncluding',\n",
       " 'education窶杯eachers',\n",
       " 'energy-producing',\n",
       " 'entrepreneurship',\n",
       " 'first-generation',\n",
       " 'gaps窶廃articularly',\n",
       " 'generations-long',\n",
       " 'government-funded',\n",
       " 'government-to-government',\n",
       " 'hydrofluorocarbons',\n",
       " 'inequality窶背here',\n",
       " 'inflation窶蚤gainst',\n",
       " 'institutionalization',\n",
       " 'institutions窶芭ost',\n",
       " 'intergenerational',\n",
       " 'locally-tailored',\n",
       " 'minority-serving',\n",
       " 'multigenerational',\n",
       " 'multimillionaire',\n",
       " 'neighborhood-serving',\n",
       " 'non-discrimination',\n",
       " 'overturn窶杷ederal',\n",
       " 'partners窶把ountries',\n",
       " 'people窶琶ncluding',\n",
       " 'police-community',\n",
       " 'responsibilities',\n",
       " 'safety窶琶ncluding',\n",
       " 'school-to-prison',\n",
       " 'sector窶廃articularly',\n",
       " 'self-determination',\n",
       " 'self-sufficiency',\n",
       " 'students窶廃articularly',\n",
       " 'tribes窶杯hroughout',\n",
       " 'violence窶琶ncluding']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " V = set(text_dem_platform_2016)\n",
    " long_words = [w for w in V if len(w) > 15]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cf932c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American',\n",
       " 'Americans',\n",
       " 'Congress',\n",
       " 'Democratic',\n",
       " 'Democrats',\n",
       " 'Department',\n",
       " 'National',\n",
       " 'President',\n",
       " 'Republican',\n",
       " 'Republicans',\n",
       " 'Security',\n",
       " 'affordable',\n",
       " 'appropriate',\n",
       " 'assistance',\n",
       " 'barriers',\n",
       " 'benefits',\n",
       " 'business',\n",
       " 'businesses',\n",
       " 'challenges',\n",
       " 'childcare',\n",
       " 'children',\n",
       " 'citizens',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'companies',\n",
       " 'comprehensive',\n",
       " 'continue',\n",
       " 'corporations',\n",
       " 'countries',\n",
       " 'creating',\n",
       " 'criminal',\n",
       " 'critical',\n",
       " 'cultural',\n",
       " 'dangerous',\n",
       " 'democracy',\n",
       " 'development',\n",
       " 'disabilities',\n",
       " 'disability',\n",
       " 'discrimination',\n",
       " 'disproportionately',\n",
       " 'economic',\n",
       " 'education',\n",
       " 'effective',\n",
       " 'employment',\n",
       " 'encourage',\n",
       " 'enforcement',\n",
       " 'ensuring',\n",
       " 'especially',\n",
       " 'expanding',\n",
       " 'families',\n",
       " 'fighting',\n",
       " 'financial',\n",
       " 'fundamental',\n",
       " 'good-paying',\n",
       " 'government',\n",
       " 'high-quality',\n",
       " 'historic',\n",
       " 'immigrants',\n",
       " 'immigration',\n",
       " 'important',\n",
       " 'including',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'individuals',\n",
       " 'infrastructure',\n",
       " 'innovation',\n",
       " 'institutions',\n",
       " 'insurance',\n",
       " 'interests',\n",
       " 'international',\n",
       " 'investment',\n",
       " 'investments',\n",
       " 'leadership',\n",
       " 'long-term',\n",
       " 'low-income',\n",
       " 'maintain',\n",
       " 'manufacturing',\n",
       " 'meaningful',\n",
       " 'military',\n",
       " 'millions',\n",
       " 'national',\n",
       " 'necessary',\n",
       " 'opportunities',\n",
       " 'opportunity',\n",
       " 'partners',\n",
       " 'policies',\n",
       " 'political',\n",
       " 'possible',\n",
       " 'potential',\n",
       " 'practices',\n",
       " 'preserve',\n",
       " 'prevention',\n",
       " 'principles',\n",
       " 'programs',\n",
       " 'progress',\n",
       " 'promoting',\n",
       " 'protecting',\n",
       " 'protections',\n",
       " 'providing',\n",
       " 'recognize',\n",
       " 'religious',\n",
       " 'reproductive',\n",
       " 'research',\n",
       " 'resources',\n",
       " 'security',\n",
       " 'services',\n",
       " 'stability',\n",
       " 'standards',\n",
       " 'strategic',\n",
       " 'strengthen',\n",
       " 'stronger',\n",
       " 'students',\n",
       " 'teachers',\n",
       " 'technology',\n",
       " 'terrorism',\n",
       " 'together',\n",
       " 'training',\n",
       " 'treatment',\n",
       " 'unacceptable',\n",
       " 'universal',\n",
       " 'veterans',\n",
       " 'violence',\n",
       " 'workforce']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist5 = FreqDist(text_dem_platform_2016)\n",
    "sorted(w for w in set(text_dem_platform_2016) if len(w) > 7 and fdist5[w] > 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f91c0def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; Donald Trump; health care; Democrats believe; climate\n",
      "change; clean energy; President Obama; middle class; Democratic Party;\n",
      "good-paying jobs; Wall Street; make sure; Social Security; federal\n",
      "government; human rights; small business; mental health; 21st century;\n",
      "Middle East; Puerto Rico\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "text_dem_platform_2016.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edb4a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 23 samples and 28686 outcomes>\n"
     ]
    }
   ],
   "source": [
    "[len(w) for w in text_dem_platform_2016]\n",
    "fdist = FreqDist(len(w) for w in text_dem_platform_2016)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e72f9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({3: 4471, 2: 4087, 4: 3576, 1: 2941, 6: 2662, 7: 2527, 5: 2309, 8: 1848, 9: 1680, 10: 972, ...})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93dc9794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4471),\n",
       " (2, 4087),\n",
       " (4, 3576),\n",
       " (1, 2941),\n",
       " (6, 2662),\n",
       " (7, 2527),\n",
       " (5, 2309),\n",
       " (8, 1848),\n",
       " (9, 1680),\n",
       " (10, 972),\n",
       " (11, 683),\n",
       " (12, 405),\n",
       " (13, 231),\n",
       " (14, 136),\n",
       " (16, 57),\n",
       " (15, 44),\n",
       " (18, 19),\n",
       " (17, 18),\n",
       " (19, 7),\n",
       " (20, 6),\n",
       " (24, 3),\n",
       " (22, 2),\n",
       " (21, 2)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ceeab0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62bfaf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4471"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "697e2cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15586000139440842"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.freq(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "something not working probably it should be a txt file\n",
    "section 1 chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9200978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1693064f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/home/maciek/nltk_data/corpora/gutenberg/Preamble'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gutenberg\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mgutenberg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_dem_platform_2016\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m num_sents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gutenberg\u001b[38;5;241m.\u001b[39msents(text_dem_platform_2016))\n\u001b[1;32m      4\u001b[0m num_vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m gutenberg\u001b[38;5;241m.\u001b[39mwords(text_dem_platform_2016)))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/reader/plaintext.py:76\u001b[0m, in \u001b[0;36mPlaintextCorpusReader.words\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    :return: the given file(s) as a list of words\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m        and punctuation symbols.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    :rtype: list(str)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m concat(\n\u001b[1;32m     74\u001b[0m         [\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCorpusView(path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_word_block, encoding\u001b[38;5;241m=\u001b[39menc)\n\u001b[0;32m---> 76\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (path, enc, fileid) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m         ]\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/reader/api.py:195\u001b[0m, in \u001b[0;36mCorpusReader.abspaths\u001b[0;34m(self, fileids, include_encoding, include_fileid)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileids, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    193\u001b[0m     fileids \u001b[38;5;241m=\u001b[39m [fileids]\n\u001b[0;32m--> 195\u001b[0m paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root\u001b[38;5;241m.\u001b[39mjoin(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids]\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_encoding \u001b[38;5;129;01mand\u001b[39;00m include_fileid:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(paths, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids], fileids))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/reader/api.py:195\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileids, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    193\u001b[0m     fileids \u001b[38;5;241m=\u001b[39m [fileids]\n\u001b[0;32m--> 195\u001b[0m paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids]\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_encoding \u001b[38;5;129;01mand\u001b[39;00m include_fileid:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(paths, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids], fileids))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:334\u001b[0m, in \u001b[0;36mFileSystemPathPointer.join\u001b[0;34m(self, fileid)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileid):\n\u001b[1;32m    333\u001b[0m     _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, fileid)\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileSystemPathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     40\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args[\u001b[38;5;241m0\u001b[39m], add_py3_data(args[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:312\u001b[0m, in \u001b[0;36mFileSystemPathPointer.__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    310\u001b[0m _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(_path)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(_path):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m _path)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m _path\n",
      "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/home/maciek/nltk_data/corpora/gutenberg/Preamble'"
     ]
    }
   ],
   "source": [
    "\n",
    "num_chars = len(text_dem_platform_2016)\n",
    "num_sents = len(gutenberg.sents(text_dem_platform_2016))\n",
    "num_vocab = len(set(w.lower() for w in gutenberg.words(text_dem_platform_2016)))\n",
    "print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d381e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.8 and 1,9 in 2nd chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001dfb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "usefull function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70531e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual = text_vocab - english_vocab\n",
    "    return sorted(unusual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97728908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aapi',\n",
       " 'abandoning',\n",
       " 'abortions',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'aca',\n",
       " 'accommodations',\n",
       " 'accomplishments',\n",
       " 'accounts',\n",
       " 'accrues',\n",
       " 'accumulated',\n",
       " 'achievements',\n",
       " 'achieving',\n",
       " 'acquires',\n",
       " 'acs',\n",
       " 'actions',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'addictions',\n",
       " 'addictionwe',\n",
       " 'adding',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adjustments',\n",
       " 'adults',\n",
       " 'advances',\n",
       " 'adversaries',\n",
       " 'advisors',\n",
       " 'advocating',\n",
       " 'affairs',\n",
       " 'affiliates',\n",
       " 'affording',\n",
       " 'afghanistan',\n",
       " 'afghanistanin',\n",
       " 'africa',\n",
       " 'agencies',\n",
       " 'ages',\n",
       " 'agreements',\n",
       " 'aids',\n",
       " 'ailments',\n",
       " 'aims',\n",
       " 'airports',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienating',\n",
       " 'allegations',\n",
       " 'alliances',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alternatives',\n",
       " 'alzheimer',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'americasthe',\n",
       " 'americawe',\n",
       " 'americorps',\n",
       " 'anticompetitive',\n",
       " 'appeals',\n",
       " 'applicants',\n",
       " 'applies',\n",
       " 'appointing',\n",
       " 'approaches',\n",
       " 'appropriations',\n",
       " 'aqim',\n",
       " 'areas',\n",
       " 'areasdemocrats',\n",
       " 'arrangements',\n",
       " 'arrivals',\n",
       " 'arriving',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'asia',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'assad',\n",
       " 'assistancewe',\n",
       " 'assisting',\n",
       " 'assumes',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attending',\n",
       " 'aumf',\n",
       " 'authorities',\n",
       " 'autocrats',\n",
       " 'automobiles',\n",
       " 'avenues',\n",
       " 'awards',\n",
       " 'backgrounds',\n",
       " 'backlogs',\n",
       " 'ballots',\n",
       " 'bankrupting',\n",
       " 'banks',\n",
       " 'banned',\n",
       " 'barriers',\n",
       " 'bars',\n",
       " 'basest',\n",
       " 'behindwe',\n",
       " 'beijing',\n",
       " 'beliefs',\n",
       " 'believes',\n",
       " 'benefits',\n",
       " 'biases',\n",
       " 'biden',\n",
       " 'bie',\n",
       " 'billionaires',\n",
       " 'billions',\n",
       " 'bills',\n",
       " 'bites',\n",
       " 'bled',\n",
       " 'boards',\n",
       " 'boilers',\n",
       " 'boko',\n",
       " 'bonds',\n",
       " 'boosted',\n",
       " 'boosting',\n",
       " 'booths',\n",
       " 'borders',\n",
       " 'borrowers',\n",
       " 'boundaries',\n",
       " 'boys',\n",
       " 'brady',\n",
       " 'breaks',\n",
       " 'bridges',\n",
       " 'brighter',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'broadband',\n",
       " 'broader',\n",
       " 'brownfields',\n",
       " 'buckley',\n",
       " 'budged',\n",
       " 'bullied',\n",
       " 'burma',\n",
       " 'businesses',\n",
       " 'businessesthe',\n",
       " 'buying',\n",
       " 'called',\n",
       " 'cameras',\n",
       " 'campuses',\n",
       " 'capabilities',\n",
       " 'cards',\n",
       " 'caredemocrats',\n",
       " 'careers',\n",
       " 'caregiver',\n",
       " 'caregivers',\n",
       " 'caregiving',\n",
       " 'caring',\n",
       " 'cars',\n",
       " 'cashing',\n",
       " 'causes',\n",
       " 'centers',\n",
       " 'centerswe',\n",
       " 'cfpb',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'changing',\n",
       " 'characteristics',\n",
       " 'checks',\n",
       " 'cherished',\n",
       " 'chiefs',\n",
       " 'childcare',\n",
       " 'childdemocrats',\n",
       " 'children',\n",
       " 'choices',\n",
       " 'christians',\n",
       " 'chﾃ｡vez',\n",
       " 'cities',\n",
       " 'citizens',\n",
       " 'claims',\n",
       " 'clarifying',\n",
       " 'clauses',\n",
       " 'cleanest',\n",
       " 'clients',\n",
       " 'climates',\n",
       " 'clinics',\n",
       " 'closing',\n",
       " 'coaches',\n",
       " 'coasts',\n",
       " 'codes',\n",
       " 'colleagues',\n",
       " 'collecting',\n",
       " 'colleges',\n",
       " 'colombia',\n",
       " 'combating',\n",
       " 'combats',\n",
       " 'combatting',\n",
       " 'comments',\n",
       " 'commitments',\n",
       " 'committed',\n",
       " 'communications',\n",
       " 'communities',\n",
       " 'companies',\n",
       " 'compared',\n",
       " 'complicit',\n",
       " 'components',\n",
       " 'concerns',\n",
       " 'conditions',\n",
       " 'conducted',\n",
       " 'conflicts',\n",
       " 'connecting',\n",
       " 'connections',\n",
       " 'consequences',\n",
       " 'consumers',\n",
       " 'containing',\n",
       " 'contaminants',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'contracting',\n",
       " 'contractors',\n",
       " 'contracts',\n",
       " 'contrasts',\n",
       " 'contributes',\n",
       " 'contributing',\n",
       " 'contributions',\n",
       " 'controlled',\n",
       " 'cooperate',\n",
       " 'cooperation',\n",
       " 'coordinate',\n",
       " 'coordinated',\n",
       " 'coordinating',\n",
       " 'coordination',\n",
       " 'corporations',\n",
       " 'costs',\n",
       " 'costsit',\n",
       " 'counseling',\n",
       " 'counted',\n",
       " 'countered',\n",
       " 'counterproductive',\n",
       " 'counties',\n",
       " 'countries',\n",
       " 'couples',\n",
       " 'courted',\n",
       " 'courts',\n",
       " 'cowers',\n",
       " 'created',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'creators',\n",
       " 'crimes',\n",
       " 'criminalization',\n",
       " 'criminals',\n",
       " 'crippled',\n",
       " 'crumbling',\n",
       " 'ctc',\n",
       " 'culturedemocrats',\n",
       " 'currencies',\n",
       " 'cuts',\n",
       " 'cyberattacks',\n",
       " 'cybersecurity',\n",
       " 'cyberspace',\n",
       " 'cycles',\n",
       " 'cyprus',\n",
       " 'cﾃｩsar',\n",
       " 'damaged',\n",
       " 'dealers',\n",
       " 'deals',\n",
       " 'debtas',\n",
       " 'debts',\n",
       " 'decades',\n",
       " 'decisions',\n",
       " 'decreased',\n",
       " 'decreases',\n",
       " 'decriminalize',\n",
       " 'dedicated',\n",
       " 'defaulting',\n",
       " 'defeating',\n",
       " 'defeatists',\n",
       " 'defenders',\n",
       " 'defending',\n",
       " 'defenses',\n",
       " 'deferrals',\n",
       " 'defining',\n",
       " 'defund',\n",
       " 'degrees',\n",
       " 'delays',\n",
       " 'delegitimize',\n",
       " 'delivering',\n",
       " 'democrats',\n",
       " 'demonization',\n",
       " 'demonstrates',\n",
       " 'demonstrating',\n",
       " 'denied',\n",
       " 'deniers',\n",
       " 'denies',\n",
       " 'depends',\n",
       " 'deploying',\n",
       " 'deployments',\n",
       " 'deportations',\n",
       " 'deposits',\n",
       " 'deserves',\n",
       " 'destabilizing',\n",
       " 'detentions',\n",
       " 'determining',\n",
       " 'developed',\n",
       " 'developing',\n",
       " 'developments',\n",
       " 'diagnosed',\n",
       " 'dictators',\n",
       " 'differences',\n",
       " 'directing',\n",
       " 'directs',\n",
       " 'disabilities',\n",
       " 'disabilitiesno',\n",
       " 'disadvantaged',\n",
       " 'disaggregated',\n",
       " 'disasters',\n",
       " 'discharged',\n",
       " 'discharges',\n",
       " 'discredited',\n",
       " 'discriminates',\n",
       " 'diseases',\n",
       " 'dismantles',\n",
       " 'disorders',\n",
       " 'disparities',\n",
       " 'displaced',\n",
       " 'districts',\n",
       " 'doctors',\n",
       " 'doj',\n",
       " 'dollars',\n",
       " 'downsize',\n",
       " 'drainages',\n",
       " 'dreamers',\n",
       " 'dreams',\n",
       " 'dredged',\n",
       " 'drowning',\n",
       " 'drugs',\n",
       " 'dues',\n",
       " 'earned',\n",
       " 'eastin',\n",
       " 'economies',\n",
       " 'ecosystems',\n",
       " 'educating',\n",
       " 'educations',\n",
       " 'educators',\n",
       " 'efforts',\n",
       " 'eisenhower',\n",
       " 'eitc',\n",
       " 'elders',\n",
       " 'elections',\n",
       " 'eliminating',\n",
       " 'emerging',\n",
       " 'emissions',\n",
       " 'emphasizing',\n",
       " 'employees',\n",
       " 'employers',\n",
       " 'empowering',\n",
       " 'enabling',\n",
       " 'enacted',\n",
       " 'enacting',\n",
       " 'enacts',\n",
       " 'encourages',\n",
       " 'endangered',\n",
       " 'ends',\n",
       " 'enforcing',\n",
       " 'engineers',\n",
       " 'engines',\n",
       " 'enjoyed',\n",
       " 'ensured',\n",
       " 'ensures',\n",
       " 'ensuring',\n",
       " 'entered',\n",
       " 'enterprises',\n",
       " 'entrepreneurs',\n",
       " 'epa',\n",
       " 'epidemics',\n",
       " 'equipped',\n",
       " 'establishing',\n",
       " 'estates',\n",
       " 'estimated',\n",
       " 'ethnicity',\n",
       " 'europe',\n",
       " 'evaluations',\n",
       " 'everglades',\n",
       " 'evicted',\n",
       " 'exacerbating',\n",
       " 'examples',\n",
       " 'exceeds',\n",
       " 'exchanges',\n",
       " 'executives',\n",
       " 'exercising',\n",
       " 'existing',\n",
       " 'exists',\n",
       " 'exonerations',\n",
       " 'expands',\n",
       " 'expenses',\n",
       " 'experiences',\n",
       " 'experiencing',\n",
       " 'experts',\n",
       " 'explosives',\n",
       " 'extends',\n",
       " 'externalities',\n",
       " 'extremists',\n",
       " 'faces',\n",
       " 'facilities',\n",
       " 'factors',\n",
       " 'failed',\n",
       " 'faiths',\n",
       " 'families',\n",
       " 'familiesdemocrats',\n",
       " 'familieswe',\n",
       " 'farmers',\n",
       " 'farms',\n",
       " 'farmworkers',\n",
       " 'fastest',\n",
       " 'fatca',\n",
       " 'fbar',\n",
       " 'feeds',\n",
       " 'fees',\n",
       " 'fewer',\n",
       " 'fewest',\n",
       " 'fighters',\n",
       " 'files',\n",
       " 'financing',\n",
       " 'fingerprints',\n",
       " 'firearms',\n",
       " 'firefighters',\n",
       " 'firms',\n",
       " 'fisheries',\n",
       " 'fleeing',\n",
       " 'floods',\n",
       " 'flourished',\n",
       " 'focused',\n",
       " 'forces',\n",
       " 'forests',\n",
       " 'forges',\n",
       " 'forms',\n",
       " 'formulating',\n",
       " 'founded',\n",
       " 'fracturing',\n",
       " 'freedoms',\n",
       " 'friends',\n",
       " 'ftc',\n",
       " 'fuels',\n",
       " 'funding',\n",
       " 'futures',\n",
       " 'gained',\n",
       " 'gapamerica',\n",
       " 'gaps',\n",
       " 'gases',\n",
       " 'gathered',\n",
       " 'generations',\n",
       " 'gerrymandering',\n",
       " 'gets',\n",
       " 'girls',\n",
       " 'gives',\n",
       " 'goals',\n",
       " 'gouging',\n",
       " 'governed',\n",
       " 'governments',\n",
       " 'governors',\n",
       " 'granting',\n",
       " 'grants',\n",
       " 'greatest',\n",
       " 'greenest',\n",
       " 'gridlock',\n",
       " 'gridlocked',\n",
       " 'groundbreaking',\n",
       " 'groups',\n",
       " 'grows',\n",
       " 'guam',\n",
       " 'guantﾃ｡namo',\n",
       " 'guaranteed',\n",
       " 'guaranteeing',\n",
       " 'guarantees',\n",
       " 'guided',\n",
       " 'guidelines',\n",
       " 'guns',\n",
       " 'gutting',\n",
       " 'haiti',\n",
       " 'haitians',\n",
       " 'halliburton',\n",
       " 'hallmarks',\n",
       " 'hamas',\n",
       " 'hands',\n",
       " 'haram',\n",
       " 'hardest',\n",
       " 'hardworking',\n",
       " 'harmed',\n",
       " 'has',\n",
       " 'havens',\n",
       " 'having',\n",
       " 'hawai',\n",
       " 'hawaiians',\n",
       " 'hazards',\n",
       " 'hbcus',\n",
       " 'heads',\n",
       " 'healthamerica',\n",
       " 'healthinvestment',\n",
       " 'healthwe',\n",
       " 'heard',\n",
       " 'held',\n",
       " 'helms',\n",
       " 'helped',\n",
       " 'herbicides',\n",
       " 'hezbollah',\n",
       " 'hhs',\n",
       " 'hiding',\n",
       " 'highs',\n",
       " 'hiring',\n",
       " 'hiv',\n",
       " 'holders',\n",
       " 'holds',\n",
       " 'homebuyers',\n",
       " 'homegrown',\n",
       " 'homeowners',\n",
       " 'homeownership',\n",
       " 'homeownershipwhereas',\n",
       " 'homes',\n",
       " 'honed',\n",
       " 'honored',\n",
       " 'honoring',\n",
       " 'horrified',\n",
       " 'hospitals',\n",
       " 'hottest',\n",
       " 'hours',\n",
       " 'households',\n",
       " 'hubs',\n",
       " 'huerta',\n",
       " 'humanities',\n",
       " 'hundreds',\n",
       " 'hurts',\n",
       " 'hyde',\n",
       " 'hydrofluorocarbons',\n",
       " 'hype',\n",
       " 'ideas',\n",
       " 'identities',\n",
       " 'ii',\n",
       " 'illnesses',\n",
       " 'immigrants',\n",
       " 'impacting',\n",
       " 'impacts',\n",
       " 'implemented',\n",
       " 'implementing',\n",
       " 'importing',\n",
       " 'improved',\n",
       " 'improvements',\n",
       " 'improves',\n",
       " 'incarcerated',\n",
       " 'incentives',\n",
       " 'incentivize',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'incomes',\n",
       " 'increased',\n",
       " 'increases',\n",
       " 'indians',\n",
       " 'individuals',\n",
       " 'industries',\n",
       " 'infections',\n",
       " 'informs',\n",
       " 'infrastructureif',\n",
       " 'ingredients',\n",
       " 'initiatives',\n",
       " 'injuries',\n",
       " 'injustices',\n",
       " 'inspires',\n",
       " 'installed',\n",
       " 'institutes',\n",
       " 'institutions',\n",
       " 'institutionsdemocrats',\n",
       " 'institutionswe',\n",
       " 'instruments',\n",
       " 'insurers',\n",
       " 'insuring',\n",
       " 'integrated',\n",
       " 'interconnected',\n",
       " 'interests',\n",
       " 'intergenerational',\n",
       " 'internet',\n",
       " 'inventors',\n",
       " 'inversions',\n",
       " 'investigations',\n",
       " 'investing',\n",
       " 'investments',\n",
       " 'investors',\n",
       " 'invests',\n",
       " 'invoked',\n",
       " 'iranwe',\n",
       " 'islamophobia',\n",
       " 'islanders',\n",
       " 'islands',\n",
       " 'israelis',\n",
       " 'issues',\n",
       " 'itliong',\n",
       " 'jails',\n",
       " 'jobs',\n",
       " 'jobswe',\n",
       " 'journalists',\n",
       " 'judges',\n",
       " 'judgeswe',\n",
       " 'judiciaries',\n",
       " 'justicedemocrats',\n",
       " 'keeps',\n",
       " 'kennedy',\n",
       " 'kinds',\n",
       " 'korea',\n",
       " 'koreanorth',\n",
       " 'laboratories',\n",
       " 'labordemocrats',\n",
       " 'lags',\n",
       " 'lakes',\n",
       " 'landowners',\n",
       " 'lands',\n",
       " 'landscapes',\n",
       " 'languages',\n",
       " 'larger',\n",
       " 'largest',\n",
       " 'latino',\n",
       " 'latinos',\n",
       " 'launched',\n",
       " 'laws',\n",
       " 'lawsuits',\n",
       " 'lawyers',\n",
       " 'lcam',\n",
       " 'leaders',\n",
       " 'leadershipclimate',\n",
       " 'learners',\n",
       " 'lebanon',\n",
       " 'legislatures',\n",
       " 'lenders',\n",
       " 'lending',\n",
       " 'levels',\n",
       " 'lgbt',\n",
       " 'liberties',\n",
       " 'licenses',\n",
       " 'lights',\n",
       " 'limitations',\n",
       " 'limits',\n",
       " 'lines',\n",
       " 'lingering',\n",
       " 'lives',\n",
       " 'loans',\n",
       " 'lobbying',\n",
       " 'localities',\n",
       " 'located',\n",
       " 'locations',\n",
       " 'longest',\n",
       " 'loopholes',\n",
       " 'losses',\n",
       " 'loved',\n",
       " 'lowers',\n",
       " 'lowest',\n",
       " 'machines',\n",
       " 'magazines',\n",
       " 'maintaining',\n",
       " 'maintains',\n",
       " 'makers',\n",
       " 'makes',\n",
       " 'managers',\n",
       " 'managing',\n",
       " 'mandating',\n",
       " 'manufactured',\n",
       " 'manufacturers',\n",
       " 'manufacturing',\n",
       " 'marched',\n",
       " 'margins',\n",
       " 'marketplaces',\n",
       " 'markets',\n",
       " 'mascots',\n",
       " 'matched',\n",
       " 'materials',\n",
       " 'matters',\n",
       " 'means',\n",
       " 'measures',\n",
       " 'mechanisms',\n",
       " 'medicaid',\n",
       " 'medicare',\n",
       " 'medications',\n",
       " 'medicines',\n",
       " 'meets',\n",
       " 'members',\n",
       " 'membersour',\n",
       " 'mentoring',\n",
       " 'mentors',\n",
       " 'methods',\n",
       " 'metro',\n",
       " 'mexicans',\n",
       " 'mexico',\n",
       " 'midterm',\n",
       " 'millionaires',\n",
       " 'minorities',\n",
       " 'minoritieswe',\n",
       " 'mired',\n",
       " 'missions',\n",
       " 'mistreated',\n",
       " 'models',\n",
       " 'modernized',\n",
       " 'modernizing',\n",
       " 'mortgages',\n",
       " 'movements',\n",
       " 'multigenerational',\n",
       " 'muslim',\n",
       " 'muslims',\n",
       " 'nasa',\n",
       " 'nations',\n",
       " 'nationswe',\n",
       " 'natives',\n",
       " 'nato',\n",
       " 'natures',\n",
       " 'needed',\n",
       " 'negotiated',\n",
       " 'negotiating',\n",
       " 'negotiations',\n",
       " 'neighborhoods',\n",
       " 'neighbors',\n",
       " 'networks',\n",
       " 'nonviolent',\n",
       " 'norms',\n",
       " 'npt',\n",
       " 'numbers',\n",
       " 'numeracy',\n",
       " 'nurses',\n",
       " 'obama',\n",
       " 'obligations',\n",
       " 'occurred',\n",
       " 'occurs',\n",
       " 'oceans',\n",
       " 'offenders',\n",
       " 'offers',\n",
       " 'officers',\n",
       " 'offices',\n",
       " 'officials',\n",
       " 'ones',\n",
       " 'online',\n",
       " 'operates',\n",
       " 'operations',\n",
       " 'opioid',\n",
       " 'opportunities',\n",
       " 'options',\n",
       " 'organizations',\n",
       " 'orientations',\n",
       " 'osama',\n",
       " 'others',\n",
       " 'outbreaks',\n",
       " 'outcomes',\n",
       " 'outraged',\n",
       " 'outsourced',\n",
       " 'outsourcing',\n",
       " 'overarching',\n",
       " 'owners',\n",
       " 'pacs',\n",
       " 'paid',\n",
       " 'pakistan',\n",
       " 'palestinians',\n",
       " 'pandemics',\n",
       " 'panels',\n",
       " 'parachutes',\n",
       " 'parents',\n",
       " 'parks',\n",
       " 'participants',\n",
       " 'parties',\n",
       " 'partners',\n",
       " 'partnerships',\n",
       " 'parts',\n",
       " 'passed',\n",
       " 'pathways',\n",
       " 'patients',\n",
       " 'patterns',\n",
       " 'paycheck',\n",
       " 'payments',\n",
       " 'pays',\n",
       " 'peacebuilding',\n",
       " 'peers',\n",
       " 'penalized',\n",
       " 'penalties',\n",
       " 'pensions',\n",
       " 'peopledemocrats',\n",
       " 'peoples',\n",
       " 'peoplethe',\n",
       " 'percentages',\n",
       " 'periodicals',\n",
       " 'permitting',\n",
       " 'perpetrators',\n",
       " 'persons',\n",
       " 'pesticides',\n",
       " 'pharmacies',\n",
       " 'pharmacists',\n",
       " 'philadelphia',\n",
       " 'phones',\n",
       " 'picking',\n",
       " 'pillars',\n",
       " 'pipes',\n",
       " 'places',\n",
       " 'plaguing',\n",
       " 'planned',\n",
       " 'planning',\n",
       " 'plans',\n",
       " 'plants',\n",
       " 'playing',\n",
       " 'plays',\n",
       " 'plcaa',\n",
       " 'pluribus',\n",
       " 'policies',\n",
       " 'policing',\n",
       " 'ponzi',\n",
       " 'poorer',\n",
       " 'poorest',\n",
       " 'populations',\n",
       " 'poses',\n",
       " 'positions',\n",
       " 'powers',\n",
       " 'practices',\n",
       " 'practitioners',\n",
       " 'praises',\n",
       " 'pregnancies',\n",
       " 'premiums',\n",
       " 'prescribers',\n",
       " 'prescriptions',\n",
       " 'presented',\n",
       " 'preserving',\n",
       " 'prevailing',\n",
       " 'preventing',\n",
       " 'prevents',\n",
       " 'prices',\n",
       " 'principled',\n",
       " 'principles',\n",
       " 'prioritize',\n",
       " 'prioritized',\n",
       " 'prioritizes',\n",
       " 'prisoners',\n",
       " 'prisons',\n",
       " 'privacydemocrats',\n",
       " 'privatize',\n",
       " 'privatizing',\n",
       " 'privileges',\n",
       " 'proactive',\n",
       " 'proactively',\n",
       " 'problems',\n",
       " 'procedures',\n",
       " 'proceedings',\n",
       " 'processes',\n",
       " 'processing',\n",
       " 'producers',\n",
       " 'products',\n",
       " 'professionals',\n",
       " 'profiling',\n",
       " 'profits',\n",
       " 'profitscorporate',\n",
       " 'programming',\n",
       " 'programs',\n",
       " 'prohibits',\n",
       " 'projected',\n",
       " 'projects',\n",
       " 'prolonged',\n",
       " 'promoted',\n",
       " 'promotes',\n",
       " 'promoting',\n",
       " 'promulgated',\n",
       " 'properties',\n",
       " 'proposed',\n",
       " 'proposes',\n",
       " 'propping',\n",
       " 'prosecuting',\n",
       " 'prosecutions',\n",
       " 'prospers',\n",
       " 'protected',\n",
       " 'protections',\n",
       " 'protects',\n",
       " 'proud',\n",
       " 'providers',\n",
       " 'provides',\n",
       " 'provisions',\n",
       " 'pta',\n",
       " 'puerto',\n",
       " 'purposes',\n",
       " 'pursuing',\n",
       " 'pushed',\n",
       " 'putin',\n",
       " 'puts',\n",
       " 'putting',\n",
       " 'pyongyang',\n",
       " 'qaeda',\n",
       " 'qualifications',\n",
       " 'questions',\n",
       " 'quickest',\n",
       " 'quotas',\n",
       " 'races',\n",
       " 'racismdemocrats',\n",
       " 'radicals',\n",
       " 'raids',\n",
       " 'ranchers',\n",
       " 'rates',\n",
       " 'reaffirmed',\n",
       " 'realities',\n",
       " 'realitydemocrats',\n",
       " 'rebuilding',\n",
       " 'recertification',\n",
       " 'recognized',\n",
       " 'recognizes',\n",
       " 'recognizing',\n",
       " 'records',\n",
       " 'reentry',\n",
       " 'reestablished',\n",
       " 'referred',\n",
       " 'reflects',\n",
       " 'reforming',\n",
       " 'reforms',\n",
       " 'refugees',\n",
       " 'refugeesthe',\n",
       " 'refundable',\n",
       " 'refuses',\n",
       " 'regulations',\n",
       " 'regulators',\n",
       " 'reining',\n",
       " 'reinvesting',\n",
       " 'reinvigorating',\n",
       " 'rejected',\n",
       " 'rejects',\n",
       " 'relations',\n",
       " 'relationships',\n",
       " 'relatives',\n",
       " 'religions',\n",
       " 'relying',\n",
       " 'remained',\n",
       " 'remaining',\n",
       " 'renaissancedemocrats',\n",
       " 'rents',\n",
       " 'repaired',\n",
       " 'repairing',\n",
       " 'repealing',\n",
       " 'replacing',\n",
       " 'reporting',\n",
       " 'represented',\n",
       " 'represents',\n",
       " 'republicans',\n",
       " 'required',\n",
       " 'requirements',\n",
       " 'requires',\n",
       " 'requiring',\n",
       " 'rescuing',\n",
       " 'researchdemocrats',\n",
       " 'researchers',\n",
       " 'reservations',\n",
       " 'reservists',\n",
       " 'residents',\n",
       " 'resorting',\n",
       " 'resourced',\n",
       " 'resources',\n",
       " 'respected',\n",
       " 'respects',\n",
       " 'responders',\n",
       " 'responsibilities',\n",
       " 'restaurants',\n",
       " 'restoring',\n",
       " 'restraints',\n",
       " 'restrictions',\n",
       " 'restricts',\n",
       " 'restructured',\n",
       " 'resulted',\n",
       " 'resupplying',\n",
       " 'retiree',\n",
       " 'retirees',\n",
       " 'retirementdemocrats',\n",
       " 'reunited',\n",
       " 'reviewing',\n",
       " 'revitalizing',\n",
       " 'rewards',\n",
       " 'ricans',\n",
       " 'richer',\n",
       " 'richest',\n",
       " 'rico',\n",
       " 'ricoand',\n",
       " 'rigged',\n",
       " 'rights',\n",
       " 'rightsdemocrats',\n",
       " 'rightsthe',\n",
       " 'rightswe',\n",
       " 'ripped',\n",
       " 'risks',\n",
       " 'roads',\n",
       " 'rooms',\n",
       " 'roundups',\n",
       " 'rulers',\n",
       " 'rules',\n",
       " 'runs',\n",
       " 'sacrifices',\n",
       " 'safeguarding',\n",
       " 'safeguards',\n",
       " 'safer',\n",
       " 'sales',\n",
       " 'samoa',\n",
       " 'sanctioning',\n",
       " 'sanctions',\n",
       " 'says',\n",
       " 'schedules',\n",
       " 'schools',\n",
       " 'schoolswe',\n",
       " 'sciences',\n",
       " 'scientists',\n",
       " 'scores',\n",
       " 'seas',\n",
       " 'secretaries',\n",
       " 'secrets',\n",
       " 'sectors',\n",
       " 'securing',\n",
       " 'securities',\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "unusual_words(text_dem_platform_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ed9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.1   Wordlist Corpora -> some good ideas for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e596c822",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1305505219.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [60]\u001b[0;36m\u001b[0m\n\u001b[0;31m    text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " nltk.download('averaged_perceptron_tagger')\n",
    "    text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    " nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
